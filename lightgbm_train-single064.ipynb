{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score,roc_auc_score,precision_recall_curve,roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,KFold,GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures,OneHotEncoder,LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tensorflow import keras\n",
    "import graphviz\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "from bayes_opt import BayesianOptimization\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#取消科学计数，显示小数点后1位\n",
    "pd.set_option('float_format', lambda x: '%.1f' % x)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "seed = 1121\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 1521787  columns: 23\n"
     ]
    }
   ],
   "source": [
    "trainfile = 'train.csv'\n",
    "train_data = pd.read_csv(trainfile)\n",
    "print(\"rows:\",train_data.shape[0],\" columns:\", train_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 421665  columns: 22\n"
     ]
    }
   ],
   "source": [
    "testfile = 'test.csv'\n",
    "test_data = pd.read_csv(testfile)\n",
    "print(\"rows:\",test_data.shape[0],\" columns:\", test_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改时间为小时\n",
    "def change_time(data):\n",
    "    time = data['loctm']\n",
    "    newtime = []\n",
    "    for i in time:\n",
    "        k = int(i/10000)\n",
    "        newtime.append(k)\n",
    "    data['loctm'] = newtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_time(train_data)\n",
    "change_time(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.replace(['N','Y'],[0,1])\n",
    "test_data = test_data.replace(['N','Y'],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['acqic', 'bacno', 'cano', 'conam', 'contp', 'csmcu', 'ecfg', 'etymd',\n",
      "       'flbmk', 'flg_3dsmk', 'fraud_ind', 'hcefg', 'insfg', 'iterm', 'locdt',\n",
      "       'loctm', 'mcc', 'mchno', 'ovrlt', 'scity', 'stocn', 'stscd', 'txkey',\n",
      "       'bacno__cano', 'stocn__csmcu', 'stocn__acqic', 'scity__acqic',\n",
      "       'mcc__stocn', 'mcc__scity', 'mcc__ecfg', 'mcc__mchno', 'csmcu__acqic',\n",
      "       'ecfg__stscd', 'etymd__csmcu', 'stocn__scity', 'stocn__ecfg',\n",
      "       'mcc__etymd', 'mcc__csmcu', 'mcc__acqic', 'scity__ecfg'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# features interaction 并使用 labelencoder\n",
    "cb_feature = ['bacno__cano','stocn__csmcu','stocn__acqic','scity__acqic','mcc__stocn',\n",
    "              'mcc__scity','mcc__ecfg','mcc__mchno','csmcu__acqic','ecfg__stscd',\n",
    "              'etymd__csmcu',\n",
    "              'stocn__scity','stocn__ecfg','mcc__etymd','mcc__csmcu','mcc__acqic','scity__ecfg']\n",
    "\n",
    "for feature in cb_feature:\n",
    "    f1,f2 = feature.split('__')\n",
    "    train_data[feature] = train_data[f1].astype(str) + '_' + train_data[f2].astype(str)\n",
    "    test_data[feature] = test_data[f1].astype(str) + '_' + test_data[f2].astype(str)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train_data[feature].astype(str).values) + list(test_data[feature].astype(str).values))\n",
    "    train_data[feature] = le.transform(list(train_data[feature].astype(str).values))\n",
    "    test_data[feature] = le.transform(list(test_data[feature].astype(str).values))\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['acqic', 'bacno', 'cano', 'conam', 'contp', 'csmcu', 'ecfg', 'etymd',\n",
      "       'flbmk', 'flg_3dsmk', 'fraud_ind', 'hcefg', 'insfg', 'iterm', 'locdt',\n",
      "       'loctm', 'mcc', 'mchno', 'ovrlt', 'scity', 'stocn', 'stscd', 'txkey',\n",
      "       'bacno__cano', 'stocn__csmcu', 'stocn__acqic', 'scity__acqic',\n",
      "       'mcc__stocn', 'mcc__scity', 'mcc__ecfg', 'mcc__mchno', 'csmcu__acqic',\n",
      "       'ecfg__stscd', 'etymd__csmcu', 'stocn__scity', 'stocn__ecfg',\n",
      "       'mcc__etymd', 'mcc__csmcu', 'mcc__acqic', 'scity__ecfg',\n",
      "       'acqic_count_full', 'bacno_count_full', 'cano_count_full',\n",
      "       'scity_count_full', 'mcc_count_full', 'mchno_count_full',\n",
      "       'conam_count_full', 'csmcu_count_full', 'bacno__cano_count_full',\n",
      "       'stocn__csmcu_count_full', 'stocn__acqic_count_full',\n",
      "       'scity__acqic_count_full', 'mcc__stocn_count_full',\n",
      "       'mcc__scity_count_full', 'mcc__mchno_count_full',\n",
      "       'csmcu__acqic_count_full', 'ecfg__stscd_count_full',\n",
      "       'stocn__scity_count_full', 'stocn__ecfg_count_full',\n",
      "       'scity__ecfg_count_full', 'mcc__etymd_count_full',\n",
      "       'mcc__csmcu_count_full', 'mcc__acqic_count_full'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Count Encoding \n",
    "cn_feature = ['acqic','bacno','cano','scity','mcc','mchno','conam','csmcu','bacno__cano','stocn__csmcu','stocn__acqic',\n",
    "'scity__acqic','mcc__stocn','mcc__scity','mcc__mchno','csmcu__acqic','ecfg__stscd','stocn__scity',\n",
    "              'stocn__ecfg','scity__ecfg','mcc__etymd','mcc__csmcu','mcc__acqic']\n",
    "for feature in cn_feature :\n",
    "    train_data[feature + '_count_full'] = train_data[feature].map(pd.concat([train_data[feature], test_data[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "    test_data[feature + '_count_full'] = test_data[feature].map(pd.concat([train_data[feature], test_data[feature]], ignore_index=True).value_counts(dropna=False))   \n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiwi\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['acqic', 'bacno', 'cano', 'conam', 'contp', 'csmcu', 'ecfg', 'etymd',\n",
      "       'flbmk', 'flg_3dsmk', 'fraud_ind', 'hcefg', 'insfg', 'iterm', 'locdt',\n",
      "       'loctm', 'mcc', 'mchno', 'ovrlt', 'scity', 'stocn', 'stscd', 'txkey',\n",
      "       'bacno__cano', 'stocn__csmcu', 'stocn__acqic', 'scity__acqic',\n",
      "       'mcc__stocn', 'mcc__scity', 'mcc__ecfg', 'mcc__mchno', 'csmcu__acqic',\n",
      "       'ecfg__stscd', 'etymd__csmcu', 'stocn__scity', 'stocn__ecfg',\n",
      "       'mcc__etymd', 'mcc__csmcu', 'mcc__acqic', 'scity__ecfg',\n",
      "       'acqic_count_full', 'bacno_count_full', 'cano_count_full',\n",
      "       'scity_count_full', 'mcc_count_full', 'mchno_count_full',\n",
      "       'conam_count_full', 'csmcu_count_full', 'bacno__cano_count_full',\n",
      "       'stocn__csmcu_count_full', 'stocn__acqic_count_full',\n",
      "       'scity__acqic_count_full', 'mcc__stocn_count_full',\n",
      "       'mcc__scity_count_full', 'mcc__mchno_count_full',\n",
      "       'csmcu__acqic_count_full', 'ecfg__stscd_count_full',\n",
      "       'stocn__scity_count_full', 'stocn__ecfg_count_full',\n",
      "       'scity__ecfg_count_full', 'mcc__etymd_count_full',\n",
      "       'mcc__csmcu_count_full', 'mcc__acqic_count_full',\n",
      "       'acqic_to_mean_bacno__cano', 'acqic_to_std_bacno__cano',\n",
      "       'csmcu_to_mean_bacno__cano', 'csmcu_to_std_bacno__cano',\n",
      "       'conam_to_mean_bacno__cano', 'conam_to_std_bacno__cano',\n",
      "       'loctm_to_mean_bacno__cano', 'loctm_to_std_bacno__cano',\n",
      "       'ecfg_to_mean_bacno__cano', 'ecfg_to_std_bacno__cano',\n",
      "       'etymd_to_mean_bacno__cano', 'etymd_to_std_bacno__cano',\n",
      "       'mcc_to_mean_bacno__cano', 'mcc_to_std_bacno__cano',\n",
      "       'mchno_to_mean_bacno__cano', 'mchno_to_std_bacno__cano',\n",
      "       'stocn_to_mean_bacno__cano', 'stocn_to_std_bacno__cano',\n",
      "       'scity_to_mean_bacno__cano', 'scity_to_std_bacno__cano',\n",
      "       'stscd_to_mean_bacno__cano', 'stscd_to_std_bacno__cano'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Group by  \\ train_test 需合并？\n",
    "train_test = train_data.append(test_data)\n",
    "for uid in ['bacno__cano']:\n",
    "    for feature in ['acqic','csmcu','conam','loctm','ecfg','etymd','mcc','mchno','stocn','scity','stscd']:\n",
    "        col_mean = train_test.groupby(uid)[feature].mean()\n",
    "        train_data[feature + '_to_mean_' + uid] = train_data[uid].map(col_mean)\n",
    "        test_data[feature + '_to_mean_' + uid] = test_data[uid].map(col_mean)\n",
    "              \n",
    "        col_std = train_test.groupby(uid)[feature].std(ddof = 0)\n",
    "        train_data[feature + '_to_std_' + uid] = train_data[uid].map(col_std)\n",
    "        test_data[feature + '_to_std_' + uid] = test_data[uid].map(col_std)\n",
    "print(train_data.columns)    \n",
    "#     train_data['conam_devide_mean_' + feature] = train_data['conam']/ train_data.groupby([feature])['conam'].transform('mean')\n",
    "#     test_data['conam_devide_mean_' + feature] = test_data['conam'] / test_data.groupby([feature])['conam'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1521787, 69) (421665, 69)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1521787 entries, 0 to 1521786\n",
      "Data columns (total 69 columns):\n",
      "acqic                        1521787 non-null int64\n",
      "bacno                        1521787 non-null int64\n",
      "cano                         1521787 non-null int64\n",
      "conam                        1521787 non-null float64\n",
      "csmcu                        1521787 non-null int64\n",
      "ecfg                         1521787 non-null int64\n",
      "etymd                        1521787 non-null int64\n",
      "loctm                        1521787 non-null int64\n",
      "mcc                          1521787 non-null int64\n",
      "mchno                        1521787 non-null int64\n",
      "scity                        1521787 non-null int64\n",
      "stocn                        1521787 non-null int64\n",
      "stscd                        1521787 non-null int64\n",
      "bacno__cano                  1521787 non-null int64\n",
      "stocn__csmcu                 1521787 non-null int64\n",
      "stocn__acqic                 1521787 non-null int64\n",
      "scity__acqic                 1521787 non-null int64\n",
      "mcc__stocn                   1521787 non-null int64\n",
      "mcc__scity                   1521787 non-null int64\n",
      "mcc__ecfg                    1521787 non-null int64\n",
      "mcc__mchno                   1521787 non-null int64\n",
      "csmcu__acqic                 1521787 non-null int64\n",
      "ecfg__stscd                  1521787 non-null int64\n",
      "etymd__csmcu                 1521787 non-null int64\n",
      "acqic_count_full             1521787 non-null int64\n",
      "bacno_count_full             1521787 non-null int64\n",
      "cano_count_full              1521787 non-null int64\n",
      "scity_count_full             1521787 non-null int64\n",
      "mcc_count_full               1521787 non-null int64\n",
      "mchno_count_full             1521787 non-null int64\n",
      "conam_count_full             1521787 non-null int64\n",
      "csmcu_count_full             1521787 non-null int64\n",
      "bacno__cano_count_full       1521787 non-null int64\n",
      "stocn__csmcu_count_full      1521787 non-null int64\n",
      "stocn__acqic_count_full      1521787 non-null int64\n",
      "scity__acqic_count_full      1521787 non-null int64\n",
      "mcc__stocn_count_full        1521787 non-null int64\n",
      "mcc__scity_count_full        1521787 non-null int64\n",
      "mcc__mchno_count_full        1521787 non-null int64\n",
      "csmcu__acqic_count_full      1521787 non-null int64\n",
      "ecfg__stscd_count_full       1521787 non-null int64\n",
      "stocn__scity_count_full      1521787 non-null int64\n",
      "stocn__ecfg_count_full       1521787 non-null int64\n",
      "scity__ecfg_count_full       1521787 non-null int64\n",
      "mcc__etymd_count_full        1521787 non-null int64\n",
      "mcc__csmcu_count_full        1521787 non-null int64\n",
      "mcc__acqic_count_full        1521787 non-null int64\n",
      "acqic_to_mean_bacno__cano    1521787 non-null float64\n",
      "acqic_to_std_bacno__cano     1521787 non-null float64\n",
      "csmcu_to_mean_bacno__cano    1521787 non-null float64\n",
      "csmcu_to_std_bacno__cano     1521787 non-null float64\n",
      "conam_to_mean_bacno__cano    1521787 non-null float64\n",
      "conam_to_std_bacno__cano     1521787 non-null float64\n",
      "loctm_to_mean_bacno__cano    1521787 non-null float64\n",
      "loctm_to_std_bacno__cano     1521787 non-null float64\n",
      "ecfg_to_mean_bacno__cano     1521787 non-null float64\n",
      "ecfg_to_std_bacno__cano      1521787 non-null float64\n",
      "etymd_to_mean_bacno__cano    1521787 non-null float64\n",
      "etymd_to_std_bacno__cano     1521787 non-null float64\n",
      "mcc_to_mean_bacno__cano      1521787 non-null float64\n",
      "mcc_to_std_bacno__cano       1521787 non-null float64\n",
      "mchno_to_mean_bacno__cano    1521787 non-null float64\n",
      "mchno_to_std_bacno__cano     1521787 non-null float64\n",
      "stocn_to_mean_bacno__cano    1521787 non-null float64\n",
      "stocn_to_std_bacno__cano     1521787 non-null float64\n",
      "scity_to_mean_bacno__cano    1521787 non-null float64\n",
      "scity_to_std_bacno__cano     1521787 non-null float64\n",
      "stscd_to_mean_bacno__cano    1521787 non-null float64\n",
      "stscd_to_std_bacno__cano     1521787 non-null float64\n",
      "dtypes: float64(23), int64(46)\n",
      "memory usage: 801.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1_features = list(train_data.columns)\n",
    "del_col = ['txkey','locdt','insfg','iterm','flg_3dsmk','flbmk','contp','hcefg','ovrlt','fraud_ind',\n",
    "           'stocn__scity','stocn__ecfg','scity__ecfg','mcc__etymd','mcc__csmcu','mcc__acqic']\n",
    "for col in del_col:\n",
    "    model1_features.remove(col)\n",
    "    \n",
    "X_train = train_data[model1_features]\n",
    "Y_train = train_data['fraud_ind']\n",
    "X_test = test_data[model1_features]\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cor(df1):\n",
    "    plt.figure(figsize = (20,20))\n",
    "    df_corr = df1.corr()\n",
    "    sns.heatmap(df_corr,fmt = '0.2f',annot = True,xticklabels=df_corr.columns,yticklabels=df_corr.columns,cmap=\"Reds\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20355"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['fraud_ind'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cor(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data['fraud_ind'].value_counts()[0])/(train_data['fraud_ind'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 499,\n",
    "          'min_child_weight': 0.009009297771374483,\n",
    "          'feature_fraction': 0.8931730501715401,\n",
    "          'bagging_fraction': 0.8249551970384116,#subsample\n",
    "          'min_data_in_leaf': 120,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': 47,\n",
    "          'learning_rate': 0.1,         \n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',        \n",
    "          'reg_alpha': 1.1690935357787136, #lambda_l1 \n",
    "          'reg_lambda': 1.119698800271026,  #lambda_l2\n",
    "          'n_jobs':-1, #num_threads \n",
    "          'device': 'cpu',\n",
    "          #'gpu_platform_id': 1,\n",
    "          #'gpu_device_id': 0,\n",
    "          'seed': seed,         \n",
    "          #'cat_smooth '\n",
    "          \n",
    "          'n_estimators':5000,\n",
    "          #'is_unbalance': True,\n",
    "          'scale_pos_weight':79.8717361224713\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['acqic','bacno','cano','contp','csmcu','ecfg','flbmk','flg_3dsmk','hcefg',\n",
    "           'insfg','iterm','loctm','mcc','mchno','ovrlt','scity','stocn','stscd','bacno__cano','stocn__csmcu','stocn__acqic',\n",
    "                      'scity__acqic','mcc__stocn','mcc__scity','mcc__ecfg','mcc__mchno','csmcu__acqic','mcc__etymd','mcc__csmcu','mcc__acqic','scity__ecfg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    predictions = np.zeros(len(X_test))\n",
    "    splits = 3\n",
    "    folds = GroupKFold(n_splits = splits)\n",
    "    split_groups = train_data['locdt']\n",
    "#auc = {}\n",
    "#test_feature = cb_feature + cf_feature\n",
    "#print(len(test_feature))\n",
    "#for col in test_feature:\n",
    "    feature = model1_features.copy()\n",
    "    #feature.append(col)\n",
    "    #print(feature)\n",
    "    X_train = train_data[feature].copy()\n",
    "    Y_train = train_data['fraud_ind'].copy()\n",
    "    oof = np.zeros(len(X_train))\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train.values, Y_train.values,groups=split_groups)):\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "        train_df, train_lb = X_train.iloc[trn_idx], Y_train.iloc[trn_idx]\n",
    "        valid_df, valid_lb = X_train.iloc[val_idx], Y_train.iloc[val_idx]\n",
    "        \n",
    "        trn_data = lgb.Dataset(train_df, label=train_lb)#cant use\n",
    "        val_data = lgb.Dataset(valid_df, label=valid_lb)#cant use\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "      \n",
    "        model.fit(train_df,train_lb,eval_set = [(train_df, train_lb),(valid_df, valid_lb)],\n",
    "                   eval_metric='auc',early_stopping_rounds = 200,verbose=100)\n",
    "    \n",
    "        valid_pre = model.predict_proba(valid_df)[:,1]\n",
    "        oof[val_idx] = valid_pre        \n",
    "        predictions += model.predict(X_test) / splits          \n",
    "    print(\"-\"*100,'\\r\\n') \n",
    "    predictions = [int(item>0.5) for  item in predictions]\n",
    "    print( \"oof  auc = \", roc_auc_score(Y_train, oof) )   \n",
    "    oof_threshold = [int(item>0.5) for  item in oof] \n",
    "    print( \"oof  f1 = \", f1_score(Y_train, oof_threshold))\n",
    "    print( \"confusion_matrix =\")\n",
    "    print(confusion_matrix(Y_train, oof_threshold))\n",
    "    #auc[col] = roc_auc_score(Y_train,oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果保存\n",
    "plt.hist(predictions,bins=100)\n",
    "plt.ylim((0,5000))\n",
    "plt.title('Submission')\n",
    "plt.show()\n",
    "#sampleSubmission = pd.read_csv('/content/submission_test_sample.csv')\n",
    "sampleSubmission = pd.read_csv('submission_test_sample.csv')\n",
    "sampleSubmission['fraud_ind'] = predictions\n",
    "sampleSubmission.to_csv('submission_test_lgb64.csv',index = None)\n",
    "\n",
    "print('testdata =',test_data['txkey'].count())\n",
    "print('1.34% of testdata =',round(test_data['txkey'].count()*0.0134))\n",
    "print('fraud predict =',sampleSubmission['fraud_ind'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian Optimization function for xgboost\n",
    "#specify the parameters you want to tune as keyword arguments\n",
    "def bo_tune_xgb(max_depth, gamma,min_child_weight,subsample,reg_alpha,reg_lambda):\n",
    "    params = {'max_depth': int(max_depth),\n",
    "              'gamma': gamma,\n",
    "              'n_estimators': 1000,\n",
    "              'learning_rate':0.009,\n",
    "              'min_child_weight':int(min_child_weight), \n",
    "              'colsample_bytree':0.866451818270932,\n",
    "              'subsample':subsample,\n",
    "              'reg_alpha':reg_alpha,\n",
    "              'reg_lambda':reg_lambda,\n",
    "              'eta': 0.1,\n",
    "              'missing' : -1,         \n",
    "              #'scale_pos_weight':79.8717361224713,\n",
    "              'objective' :'binary:logistic',\n",
    "              'tree_method':'gpu_hist',\n",
    "              'eval_metric': 'auc'}\n",
    "    dtrain = xgb.DMatrix(X_train, Y_train, missing=-1)\n",
    "    #Cross validating with the specified parameters in 5 folds and  iterations\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=1000, early_stopping_rounds=200, nfold=3)    \n",
    "    return cv_result['test-auc-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Invoking the Bayesian Optimizer with the specified parameters to tune\n",
    "xgb_bo = BayesianOptimization(bo_tune_xgb, {'max_depth': (47,100 ),\n",
    "                                             'gamma': (0, 1),\n",
    "                                             #'learning_rate':(0,1),\n",
    "                                             #'n_estimators':(90,101),\n",
    "                                             'min_child_weight':(1,8),\n",
    "                                            'subsample':(0.6,1),\n",
    "                                            #'colsample_bytree':(0.6,0.9),\n",
    "                                            'reg_alpha':(0.05,8),\n",
    "                                            'reg_lambda':(0.05,5),  \n",
    "                                            #'scale_pos_weight':(70,80),\n",
    "                                            })\n",
    "\n",
    "#performing Bayesian optimization for 5 iterations with 8 steps of random exploration with an #acquisition function of expected improvement\n",
    "xgb_bo.maximize(n_iter=5, init_points=8, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.9164018557425374, 'max_depth': 47.30079943766095, 'min_child_weight': 1.1330080023616476, 'reg_alpha': 0.1061287463760113, 'reg_lambda': 0.0520353205403597, 'subsample': 0.7666668970782012}\n"
     ]
    }
   ],
   "source": [
    "#Extracting the best parameters\n",
    "params = xgb_bo.max['params']\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the max_depth and n_estimator values from float to int\n",
    "params['max_depth']= int(params['max_depth'])\n",
    "#Initialize an XGBClassifier with the tuned parameters and fit the training data\n",
    "from xgboost import XGBClassifier\n",
    "classifier2 = XGBClassifier(**params).fit(text_tfidf, clean_data_train['author'])\n",
    "\n",
    "#predicting for training set\n",
    "train_p2 = classifier2.predict(text_tfidf)\n",
    "\n",
    "#Looking at the classification report\n",
    "print(classification_report(train_p2, clean_data_train['author']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
